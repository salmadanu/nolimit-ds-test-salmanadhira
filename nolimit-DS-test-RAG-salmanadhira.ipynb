{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EeGa73qfxgl"
   },
   "source": [
    "# NoLimit Data Scientist Technical Test - RAG Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cd-Mh9ydgsHw"
   },
   "source": [
    "## 0. Instalasi dependensi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ednyX-QgxWM",
    "outputId": "dfff0ae9-7bd4-49b1-cd64-448def15c79e"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pymupdf\n",
    "!pip install tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-ogq9j0gyis"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import fitz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qb7EjNkHgeN9"
   },
   "source": [
    "## 1. Ekstraksi teks dari PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QbDMN2XgfnUk",
    "outputId": "4739dedc-5078-4dc8-978e-43859bbd4e45"
   },
   "outputs": [],
   "source": [
    "# Clone repo github untuk akses file PDF\n",
    "!git clone https://github.com/salmadanu/nolimit-ds-test-salmanadhira.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vNnTiXZ5nj-R"
   },
   "outputs": [],
   "source": [
    "def extract_text_from_pdf_folder(folder_path):\n",
    "    texts = {}\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            doc = fitz.open(pdf_path)\n",
    "\n",
    "            # Ektraksi per halaman (to cite sources later on)\n",
    "            page_texts = {}\n",
    "            for page_num, page in enumerate(doc, start=1):\n",
    "                page_texts[page_num] = page.get_text()\n",
    "            doc.close()\n",
    "\n",
    "            texts[filename] = page_texts\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JCNz71vloQ0u",
    "outputId": "db133773-7e84-45b0-f3aa-1804dcf72848"
   },
   "outputs": [],
   "source": [
    "folder_path = \"/content/nolimit-ds-test-salmanadhira/dataset\"\n",
    "pdf_texts = extract_text_from_pdf_folder(folder_path)\n",
    "\n",
    "# Check\n",
    "sample_file = list(pdf_texts.keys())[0]\n",
    "print(f\"Sample File: {sample_file}\")\n",
    "print(pdf_texts[sample_file][1][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUTMmYxqp8R4"
   },
   "source": [
    "## 2. Praproses data\n",
    "Menghilangkan referensi, sitasi, header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E029tsaso8o9"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "  text = re.split(r\"\\bAcknowledgment\\b|\\bAcknowledgement\\b|\\bAcknowledgements\\b|\\bReferences\\b|\\bBibliography\\b\", text, flags=re.IGNORECASE)[0]\n",
    "  text = re.sub(r\"\\s+\", \" \", text)\n",
    "  return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qoEFRA9pNWwM",
    "outputId": "4b68cf3a-84b7-4918-b42b-d598da169235"
   },
   "outputs": [],
   "source": [
    "preprocessed_texts = {}\n",
    "for filename, pages in pdf_texts.items():\n",
    "    preprocessed_texts[filename] = {}\n",
    "    for page_num, text in pages.items():\n",
    "        preprocessed_texts[filename][page_num] = preprocess_text(text)\n",
    "\n",
    "# Check\n",
    "sample_file = list(preprocessed_texts.keys())[0]\n",
    "sample_page = list(preprocessed_texts[sample_file].keys())[0]\n",
    "print(f\"Sample File: {sample_file}\")\n",
    "print(f\"Sample Page: {sample_page}\")\n",
    "print(preprocessed_texts[sample_file][sample_page][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MiRkSwTQP0QC"
   },
   "source": [
    "## 3. Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IP_xFnW9P2nV"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def chunk_pdfs(pdf_texts, chunk_size=400, chunk_overlap=50):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    chunks = []\n",
    "    for filename, pages in pdf_texts.items():\n",
    "        for page_num, text in pages.items():\n",
    "            page_chunks = splitter.split_text(text)\n",
    "            for i, chunk in enumerate(page_chunks):\n",
    "                chunks.append({\n",
    "                    \"filename\": filename,\n",
    "                    \"page_number\": page_num,\n",
    "                    \"chunk_id\": i,\n",
    "                    \"text\": chunk\n",
    "                })\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_6TZDChP_CS",
    "outputId": "149d9035-ea73-4a28-a2b6-07b7609ebedf"
   },
   "outputs": [],
   "source": [
    "chunks = chunk_pdfs(preprocessed_texts)\n",
    "\n",
    "print(f\"Total chunks: {len(chunks)}\")\n",
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDgYpJqBUcVR"
   },
   "source": [
    "## 4. Menambahkan chunks ke database vektor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bGRusGAFSz4e",
    "outputId": "fb2259ef-837c-4829-fd77-81df6c3da221"
   },
   "outputs": [],
   "source": [
    "!pip install faiss-cpu langchain sentence-transformers langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fbf819d5",
    "outputId": "01afc069-9eaa-420c-9d57-e78712fa2232"
   },
   "outputs": [],
   "source": [
    "!pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493,
     "referenced_widgets": [
      "360895ad24124b89bf52a462ae7beae6",
      "30b79616efc2404786ad5aab69bbe020",
      "84910d77e0ce470ea053b9339121e424",
      "711f65b70fe04156b40403afd036ff6f",
      "2cb7fdef257c479b9ad116811215d329",
      "c3997d9a8dd748b98cb1048d92e80a62",
      "1d736f17531540a3b8a1060b49b7aecb",
      "9825cc0b29134a63866a4edae7acc963",
      "d9c7098de5364e238a35c6ae82cba456",
      "5c5ffcabe89d48799eafd36a5a8f7ea0",
      "e28838cc12cc40e4b43efe0d0f1caca9",
      "e3e5a032eeae4a9db96c681f46f05f0b",
      "80034b5804914f5fbd7ec30293353374",
      "77f3e829b2dc479c9cc20e06319fe3ba",
      "cb0a00001a544fb5bc9b9b78ce42a911",
      "528237464daa4861a1bee04e4dbc539a",
      "c2691b22c0ad4ca6ac89890043f30c51",
      "1d0605a6719b40fba25e3dbb5fe35abc",
      "ea33064e567d4709a56cb830a3393ec7",
      "ed29893a77ac420fa66cfffb370d837a",
      "12c71956db7e4a8887a27ba449deb3be",
      "8ab70d0c2a6e4ac29ab9997a948309fd",
      "8af609e009ad49d7b44d1f94b891de5e",
      "bc0d8c82e85c452bbe5702bc4c60deba",
      "3226e23429944b609189842d261f9fc1",
      "fe734a9790024512a386b922cadd29bc",
      "4f61d42fbbed40b688932f8b05a8d3a9",
      "f4c96d169a1f466c8b591a2b0d92d08b",
      "76f13cfaf4634b25a2ee16671a2740e9",
      "32777df95f4c4234be9ddccbce5de023",
      "9ccd231672074c99a3d810bb15138f1d",
      "ba7083d0e3f94917bebb121fa75a601d",
      "95e29b0563d14952a4365ef8a2e76619",
      "b3bd20af53fa41709541f2988a36ea86",
      "3be6aaddd18d46eab4be444d4e2f8e8d",
      "85446c49316a4362a22b8b446c443cc8",
      "cd3fa100920d455a99059c2a9f0b7c09",
      "ff32c5353c044896b1d0ed4f44b8e04d",
      "6b030e6a58a4456c94694ccd91bd19b1",
      "e8f6c8c8c0154adf82f245f13ec1c3da",
      "b89a192120fb43e093c456e39b69fcdc",
      "3d628159c6644be889b40e0410b0dba3",
      "9e6f9e52bee14bd3976b58ed763be2cc",
      "d71108d7a091474aaf3924ca204cac24",
      "7312ff28c68d4cf1956574f04a68055c",
      "b1d225a098a14939bd9e0054b10ad6e7",
      "059476b9a14147228f317101ad0cb7b8",
      "4b7dd019b975476ea18466412826c79e",
      "f80deb485b6b4470af4afe7a068a07a2",
      "eb177d92f0bd43848efc2af552dad22a",
      "58956c8c50304b12aaadaabaa2c65812",
      "e0380d95d66a47198bd200920a06f72b",
      "f715a81134ab497d9ccf523a0ac435a5",
      "822662e065414fa5963500e236a6e4d9",
      "8c544bc3c3e948eaaf1ad37038b33454",
      "ff38b00de7264235b371070eff57f5ea",
      "212d188271404e43af5fb44fc113c56a",
      "463e6ad8ff2346baa6d7950b6713c20c",
      "309c3d767c31415aa0b231eb3d566822",
      "642f9a0d322c4ed1a14f4d14e165c39a",
      "c40482e6f47b43ce91f158c52c347e9f",
      "191f3d38915c4cc4bbf8e27219f63d96",
      "bab81bc84eaf466298a2e6c689f2b6b6",
      "8a547ad1f04745809ba13730a390a709",
      "5e8c993ba57b4752b537e728f02e812e",
      "afb6370ca912462a8a561672a6598ff8",
      "f7c366fda9ae4c53b9abc3f7ddbe694c",
      "7a6fb5826636446c9f22c0e992eb5b44",
      "4f2bee42f5f34574a729ffb5cb802fc2",
      "c4b17796bccd4bd784bcbcd9adae2e07",
      "593a5f103aa24a36af67a9ac4ed708ca",
      "e621ba593c854e70b224787da104ef21",
      "033e402bacf0478ab106c6fa4612a88e",
      "d000631f5b3246f09d9094196a8c5d24",
      "1e1550f285504db4b440a5f3a77257cb",
      "a444e8b601724b64a62b568cdb7e6350",
      "86466c5fe1cf491a89a77028257cbef6",
      "cb166d68a55a4ebc8750e786d48874f0",
      "6df62e1ee6054c6eb97be8139a8ff3db",
      "a1d94f9e3bdb4a0f8bdb7b696e8eb3c0",
      "723cc18944164f198f3dec27f3b1cfa4",
      "17ec191635c44150ae90b20ee6951391",
      "8452a1ddb1e14b04a133a6d79103252b",
      "c7221c1c70154086888c05a958d83eda",
      "0515b588af05476ab93023fac03ced33",
      "aabdbd7022b44966a1ef43554183bfa9",
      "07f555c1d4a74131adb931a14c48c78e",
      "ffa0a3b468774da4b489cdf1c0f41ee6",
      "edf037f4a2224d3fb4f28edadca0b054",
      "b35055d735b346599c8cd702774baf1a",
      "69521ce26e674c9dac706dd66e4570bb",
      "35934cedff6f4bb2986554e96a26ed3d",
      "f00171d138ab4188b4d32ce04d8d3a21",
      "51460ac45e7f414ebaa9625b2d5fd8a3",
      "ec67d065afa048ca832904d5ff1cdff0",
      "dadbd908788d4b2791d30f63306a4243",
      "bb1baff61319475582363074367368c8",
      "f477c699c0844ffea997fdd68d0687a0",
      "8f21be7f788d484381f3ff1740f07c64",
      "ce0eb27f02a448978299eccef0430c77",
      "2a944eb7549f4abf954093c0b03f50a6",
      "ca7eb21b6c144545b6e69cac5f8fd170",
      "7880120a6ac74459bf6aa7fbbe7553e7",
      "18f368af73614039811cf24d9786fdef",
      "d40a42ec10314111bd28f32709e9c2de",
      "7320b9089d544ee1af112da4d15f1378",
      "bbb306b2d79b4c5db77dcc6ad079374b",
      "d868b3b420bd44cba40f462529c58165",
      "ebd66f3a186d48f4bc2ef2626dbef57d",
      "63c3c5a484794157b138d5ac553b3cf9",
      "b7662b567fb44c9a9747dbac07365c69",
      "cc28ff9bbc594edb8b4426ed2a2b40f2",
      "b1359d3066bb4004b414ca958785f914",
      "4016e69d060549929712d81e7171f673",
      "7bcb2bccece74afb8c5feca0053e3ef3",
      "461ed870a5804d46bc92f24454951824",
      "7e0a996d201b4c41a7b67e8b8bca997e",
      "a6475fc3714d479483a752a084e3006d",
      "cc589e43ad96432288fda020fb0967e1",
      "2444849db8fc4906a0beac50b5813c06",
      "c2beafdcad9f4893915e05a3e81874e4"
     ]
    },
    "id": "73d07207",
    "outputId": "fceb6efb-53de-4635-a66a-a740c451eab1"
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")\n",
    "\n",
    "def build_faiss_vectorstore(chunks):\n",
    "    texts = [chunk[\"text\"] for chunk in chunks]\n",
    "    metadatas = [{\"filename\": c[\"filename\"], \"page_number\": c[\"page_number\"], \"chunk_id\": c[\"chunk_id\"]} for c in chunks]\n",
    "\n",
    "    vectorstore = FAISS.from_texts(texts, embedding_model, metadatas=metadatas)\n",
    "    return vectorstore\n",
    "\n",
    "vectorstore = build_faiss_vectorstore(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wBJwAlseV748"
   },
   "outputs": [],
   "source": [
    "vectorstore.save_local(\"faiss_index\")\n",
    "vectorstore = FAISS.load_local(\"faiss_index\", embedding_model, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AIoPfC1-ntgf",
    "outputId": "c8735472-6d9b-47e8-a109-d93e7f31261f"
   },
   "outputs": [],
   "source": [
    "# Memeriksa apakah dokumen yang di-retrieve sudah sesuai\n",
    "query = \"What is stance detection?\"\n",
    "results = vectorstore.similarity_search(query, k=10)\n",
    "\n",
    "for res in results:\n",
    "    print(res.page_content[:200])\n",
    "    print(res.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r2gPKM64HDtS",
    "outputId": "79204ec0-ca10-45d7-f65e-aebc1c3a9432"
   },
   "outputs": [],
   "source": [
    "# Memeriksa dimensi embedding (menangani AssertionError saat deploy)\n",
    "sample_vector = embedding_model.embed_query(\"test query\")\n",
    "print(\"Embedding dimension:\", len(sample_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gijvv1D1HSM8",
    "outputId": "c3390fff-86bd-4445-f557-bc05e2df30bd"
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "print(\"FAISS index dimension:\", vectorstore.index.d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIz5apqo3ahG"
   },
   "source": [
    "## 5. Ngequery LLM\n",
    "Generate jawaban dari query berdasarkan chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ol7fBnkA4mTy",
    "outputId": "86eec71a-5ecb-45c9-e826-f2212834451d"
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "qa_pipeline = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/flan-t5-large\",\n",
    "    device=0\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=qa_pipeline)\n",
    "\n",
    "template = \"\"\"\n",
    "You are an academic assistant helping summarize research papers.\n",
    "Use the provided CONTEXT to answer the QUESTION clearly and concisely.\n",
    "- Write the answer in well-formed sentences, even if the context has fragmented text.\n",
    "- Do not copy broken words or incomplete phrases directly from the context.\n",
    "- If the question is about methods or models, list them clearly and EXPLAIN their purpose.\n",
    "- If needed, cite authors or papers mentioned in the context.\n",
    "- If the answer cannot be found in the context, say \"The context does not provide enough information.\"\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "\n",
    "def format_doc(doc):\n",
    "    meta = doc.metadata\n",
    "    source = f\"(Source: {meta.get('filename', 'unknown')}, page {meta.get('page_number', '?')})\"\n",
    "    return f\"{doc.page_content}\\n{source}\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
    "qa_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "def answer_query(query, vectorstore, k=10):\n",
    "    results = vectorstore.max_marginal_relevance_search(query, k=k, fetch_k=20)\n",
    "    context = \"\\n\\n\".join([format_doc(doc) for doc in results[:3]])\n",
    "    answer = qa_chain.run({\"context\": context, \"question\": query})\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUh4KsbaxMtn"
   },
   "source": [
    "### Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rWunTyFaGTvU"
   },
   "outputs": [],
   "source": [
    "def clean_answer(text: str) -> str:\n",
    "    text = re.sub(r\"-\\s+\", \"\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pHpoXqWX490O",
    "outputId": "cbf5f19b-4535-470c-ae06-e3b03051bda6"
   },
   "outputs": [],
   "source": [
    "query = \"What is framing analysis in computational media studies??\"\n",
    "answer = answer_query(query, vectorstore)\n",
    "answer = clean_answer(answer)\n",
    "print(answer[0].upper() + answer[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TeoyqiUlxPdN",
    "outputId": "2dc8890c-1173-4f3f-9619-543b628a753f"
   },
   "outputs": [],
   "source": [
    "query = \"How is propaganda detection defined in computational linguistics?\"\n",
    "answer = answer_query(query, vectorstore)\n",
    "answer = clean_answer(answer)\n",
    "print(answer[0].upper() + answer[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pJyLuyiRxiyG",
    "outputId": "1e2f6db7-25e0-4c7e-8449-e34d4e961b27"
   },
   "outputs": [],
   "source": [
    "query = \"What deep learning models are commonly applied to propaganda detection?\"\n",
    "answer = answer_query(query, vectorstore)\n",
    "answer = clean_answer(answer)\n",
    "print(answer[0].upper() + answer[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AdJ8is3CxoUa",
    "outputId": "3fd26a46-6120-42f6-df10-6d6e2fcde523"
   },
   "outputs": [],
   "source": [
    "query = \"How can Twitter data be preprocessed for misinformation detection?\"\n",
    "answer = answer_query(query, vectorstore)\n",
    "answer = clean_answer(answer)\n",
    "print(answer[0].upper() + answer[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "woMSNZZdxrJN",
    "outputId": "b1475ba1-1851-4709-adee-fd7e75161e99"
   },
   "outputs": [],
   "source": [
    "query = \"How is framing analysis applied to coverage of international conflicts?\"\n",
    "answer = answer_query(query, vectorstore)\n",
    "answer = clean_answer(answer)\n",
    "print(answer[0].upper() + answer[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFtEBFpzDcgH"
   },
   "source": [
    "# Interactive Q&A Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "382afbfacd32446199258a9ea58e98e9",
      "4928eb077d7a4706bbd8610ee9ecc1a4",
      "17b2eccc957d4deba60af33bb5f230f6"
     ]
    },
    "id": "DAF0N4wIDens",
    "outputId": "5be9eb6d-f293-47d1-a246-d3bd1d348565"
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "text_box = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Question on computational media analysis...',\n",
    "    description='Question:',\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "display(text_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9_-hFxPyJr-Z",
    "outputId": "e7f9f5fc-70c9-494e-a1ff-7c6d35dd3e71"
   },
   "outputs": [],
   "source": [
    "query = text_box.value\n",
    "answer = answer_query(query, vectorstore)\n",
    "answer = clean_answer(answer)\n",
    "print(answer[0].upper() + answer[1:])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
